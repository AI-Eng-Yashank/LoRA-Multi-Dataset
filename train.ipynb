{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a68dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers datasets peft accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7e6d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import (AutoTokenizer, AutoModelForSeq2SeqLM, Trainer,\n",
    "                          TrainingArguments, get_scheduler)\n",
    "from torch.optim import AdamW\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from torch.cuda.amp import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310690f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading datasets...\")\n",
    "fitness_dataset = load_dataset(\"chibbss/fitness-chat-prompt-completion-dataset\")\n",
    "code_feedback_dataset = load_dataset(\"m-a-p/CodeFeedback-Filtered-Instruction\")\n",
    "\n",
    "print(fitness_dataset)\n",
    "print(code_feedback_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23280ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset, prefix, input_col, output_col):\n",
    "    return dataset.map(lambda x: {\n",
    "        \"instruction\": f\"{prefix}: {x[input_col]}\",\n",
    "        \"output\": x[output_col]\n",
    "    })\n",
    "\n",
    "fitness_dataset = preprocess_dataset(fitness_dataset['train'], \"[fitness]\", \"instruction\", \"output\")\n",
    "code_feedback_dataset = preprocess_dataset(code_feedback_dataset['train'], \"[code_feedback]\", \"query\", \"answer\")\n",
    "\n",
    "combined_dataset = concatenate_datasets([fitness_dataset, code_feedback_dataset]).shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc55941",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"D:/testing/text_guru_model\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    inputs = examples['instruction']\n",
    "    targets = examples['output']\n",
    "    model_inputs = tokenizer(inputs, truncation=True, padding='max_length', max_length=512)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, truncation=True, padding='max_length', max_length=512)\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = combined_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['instruction', 'output']).train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b34984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading model...\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"D:/cuda/final_model\")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "print(f\"Model is on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa030971",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=5,\n",
    "    learning_rate=3e-5,\n",
    "    warmup_steps=500,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    report_to=\"tensorboard\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    max_grad_norm=1.0,\n",
    "    disable_tqdm=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd5a862",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "num_training_steps = len(tokenized_datasets['train']) // (\n",
    "    training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps\n",
    ") * training_args.num_train_epochs\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=500, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1254c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def save_checkpoint(self, output_dir=None):\n",
    "        super().save_checkpoint(output_dir)\n",
    "        checkpoints = sorted(\n",
    "            [ckpt for ckpt in os.listdir(self.args.output_dir) if ckpt.startswith(\"checkpoint\")],\n",
    "            key=lambda x: int(x.split(\"-\")[-1])\n",
    "        )\n",
    "        if len(checkpoints) > 5:\n",
    "            for ckpt_to_delete in checkpoints[:-5]:\n",
    "                shutil.rmtree(os.path.join(self.args.output_dir, ckpt_to_delete))\n",
    "                print(f\"Deleted checkpoint {ckpt_to_delete} to free up space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf841a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboard tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe56e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing Trainer...\")\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    optimizers=(optimizer, lr_scheduler)\n",
    ")\n",
    "\n",
    "last_checkpoint = None\n",
    "if os.path.isdir(training_args.output_dir):\n",
    "    last_checkpoint = max(\n",
    "        [os.path.join(training_args.output_dir, ckpt) for ckpt in os.listdir(training_args.output_dir) if ckpt.startswith(\"checkpoint\")],\n",
    "        key=os.path.getctime,\n",
    "        default=None\n",
    "    )\n",
    "\n",
    "if last_checkpoint:\n",
    "    print(f\"Resuming training from checkpoint: {last_checkpoint}\")\n",
    "else:\n",
    "    print(\"No checkpoint found, starting training from scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011953ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "trainer.train(resume_from_checkpoint=last_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b4ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating the model...\")\n",
    "metrics = trainer.evaluate()\n",
    "print(\"Evaluation Metrics:\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e651c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./text_guru_phase2\"\n",
    "print(f\"Saving the model to {save_path}...\")\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2908c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_cache(model, input_ids, past_key_values=None):\n",
    "    output = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        past_key_values=past_key_values,\n",
    "        do_sample=True,\n",
    "        max_length=100\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294931f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = save_path\n",
    "tokenizer_path = save_path\n",
    "\n",
    "print(\"Loading saved model and tokenizer...\")\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "    print(\"Model and tokenizer loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model or tokenizer: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93127852",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = [\n",
    "    \"What are some practical steps I can take to improve my overall health and well-being?\",\n",
    "    \"What are some effective strategies for staying hydrated during workouts?\",\n",
    "    \"Create a nested loop to print every combination of numbers between 0-9, excluding any combination that contains the number 5. Additionally, exclude any combination that contains a repeating digit. Implement the solution without using any built-in functions or libraries to check for repeating digits.\",\n",
    "    \"Suggest how to make the following code more readable and efficient using list comprehensions. def has_duplicates(arr): return any([arr[i] == arr[j] for i in range(len(arr)) for j in range(i + 1, len(arr))])\",\n",
    "]\n",
    "\n",
    "reference_texts = [\n",
    "    \"Develop a consistent exercise routine – Exercise is essential for physical and mental health. Aim for at least 30 minutes of physical activity five days a week. 2. Follow a healthy diet – Incorporate more fruits, vegetables, and whole grains into your diet while avoiding processed and fast foods. 3. Get enough sleep – Give your body time to rest and repair by getting the recommended seven to nine hours of sleep every night. 4. Practice relaxation techniques – Take a break to practice mindfulness, deep breathing, and other forms of relaxation to reduce stress and maintain emotional balance. 5. Talk\",\n",
    "    \"Hydration during Exercise: Drink water before, during, and after workouts. Monitor urine color for hydration status. Include electrolytes for longer sessions. Dehydration impairs performance and recovery.\",\n",
    "    \"Here is an example of a nested loop in Python to print every combination of numbers between 0-9, excluding any combination that contains the number 5 or repeating digits: ```python for i in range(10): # First digit for j in range(10): # Second digit for k in range(10): # Third digit # Checking for the conditions if i != 5 and j != 5 and k != 5 and i != j and i != k and j != k: print(i, j, k) ``` This code will generate and print every combination of three digits between 0-9 that do not contain the number 5 and do not have any repeating digits.\",\n",
    "    \"One way to make the code more readable and efficient using list comprehensions is as follows: def has_duplicates(arr): return any(arr[i] == arr[j] for i in range(len(arr)) for j in range(i + 1, len(arr))) In this version, we removed the square brackets around the list comprehension. This is because we only need to check if any element in the list comprehension is True, so there's no need to create a list of booleans. This change also improves efficiency because it avoids creating an unnecessary list in memory. The any() function can directly evaluate the generator expression without having to create a list first.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2a86bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(test_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length=200,\n",
    "        num_beams=5,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "\n",
    "decoded_outputs = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "\n",
    "for i, (inp, ref, out) in enumerate(zip(test_texts, reference_texts, decoded_outputs)):\n",
    "    print(f\"Example {i + 1}:\")\n",
    "    print(f\"Input: {inp}\")\n",
    "    print(f\"Reference: {ref}\")\n",
    "    print(f\"Output: {out}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adc644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install evaluate sacrebleu nltk rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd7e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "print(\"Calculating BLEU score...\")\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "bleu_score = bleu_metric.compute(predictions=decoded_outputs, references=[[ref] for ref in reference_texts])\n",
    "print(f\"BLEU Score: {bleu_score['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4da6e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "print(\"Calculating ROUGE scores...\")\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "rouge_scores = rouge_metric.compute(predictions=decoded_outputs, references=reference_texts)\n",
    "print(\"ROUGE Scores:\", rouge_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
